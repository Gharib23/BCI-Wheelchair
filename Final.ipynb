{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a5c7a9c",
   "metadata": {},
   "source": [
    "# Reading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Load your data\n",
    "eeg_data = pd.read_csv(\"F:/Graduation/Sessions/final/final_EEGdata.csv\")  # replace with your file path\n",
    "labels = pd.read_csv('F:/trial_labels.csv')  # replace with your file path\n",
    "\n",
    "# Select only the columns for the 4 channels\n",
    "channels = ['C3', 'C4', 'CZ', 'PZ']\n",
    "eeg_data = eeg_data[channels]\n",
    "print(eeg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23dec9b",
   "metadata": {},
   "source": [
    "# Data Segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def segment_data(data, labels, start_time, end_time, sampling_rate):\n",
    "    segment_length = (end_time - start_time) * sampling_rate\n",
    "    segments = []\n",
    "    segment_labels = []\n",
    "\n",
    "    for i, row in labels.iterrows():\n",
    "        start_index = int(row['start_time'] * sampling_rate)\n",
    "        segment = data.iloc[start_index : int(start_index + segment_length)]\n",
    "        segments.append(segment)\n",
    "        segment_labels.append(row['direction'])\n",
    "\n",
    "    return segments, np.array(segment_labels)\n",
    "\n",
    "# Define your parameters\n",
    "START_TIME = 2.5  # in seconds\n",
    "END_TIME = 7.5  # in seconds\n",
    "SAMPLING_RATE = 250  # in Hz\n",
    "\n",
    "# Segment the data\n",
    "segments, segment_labels = segment_data(eeg_data, labels, START_TIME, END_TIME, SAMPLING_RATE)\n",
    "print (segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9dbe8",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "05afb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "import pywt\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the sampling rate is defined earlier in your script\n",
    "SAMPLING_RATE = 250  # Modify as per your data's sampling rate\n",
    "\n",
    "def calculate_psd(data):\n",
    "    freqs, psd = welch(data, fs=SAMPLING_RATE)\n",
    "    return psd\n",
    "\n",
    "def calculate_hjorth(activity, mobility):\n",
    "    complexity = np.sqrt(np.diff(mobility, axis=0)**2 + mobility[:-1]**2) / mobility[:-1]\n",
    "    return complexity\n",
    "\n",
    "def calculate_wavelet_transform(data):\n",
    "    coeffs = pywt.wavedec(data, 'db4', level=5)\n",
    "    features = [np.mean(coeff**2) for coeff in coeffs]\n",
    "    return features\n",
    "\n",
    "def extract_features(segments, channels):\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        segment_features = []\n",
    "        for channel in channels:  # Iterate through each of the 4 channels\n",
    "            channel_data = segment[channel].values  # Extract data for the current channel\n",
    "            # Calculate features for this channel\n",
    "            psd = calculate_psd(channel_data)\n",
    "            wavelet = calculate_wavelet_transform(channel_data)\n",
    "            activity = np.var(channel_data)\n",
    "            mobility = np.sqrt(np.var(np.diff(channel_data)) / activity)\n",
    "            \n",
    "            # Append the features from this channel to the segment's feature vector\n",
    "            segment_features.extend([activity, mobility, *psd, *wavelet])\n",
    "        \n",
    "        # Append the feature vector for this segment to the overall feature list\n",
    "        features.append(segment_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features for each segment (assuming 'segments' is already defined and properly segmented)\n",
    "features = extract_features(segments, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34b4a1",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dee5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, segment_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1874f",
   "metadata": {},
   "source": [
    "# GUI & new-input classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2e05924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label\n",
    "from PIL import Image, ImageTk\n",
    "import pandas as pd\n",
    "\n",
    "# Global variables\n",
    "new_data = None\n",
    "channels = ['C3', 'C4', 'CZ', 'PZ']  # Update with the actual channels you're using\n",
    "\n",
    "def load_data():\n",
    "    global new_data  # Declare new_data as a global variable\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:  # Only proceed if a file was selected\n",
    "        new_data = pd.read_csv(file_path)\n",
    "        status_label.config(text=\"File loaded successfully.\")\n",
    "        \n",
    "def extract_new_features(channels):\n",
    "    new_segment_features = []\n",
    "    for channel in channels:  # Iterate through each of the 4 channels\n",
    "        channel_data = new_data[channel].values  # Extract data for the current channel\n",
    "         # Calculate features for this channel\n",
    "        psd = calculate_psd(channel_data)\n",
    "        wavelet = calculate_wavelet_transform(channel_data)\n",
    "        activity = np.var(channel_data)\n",
    "        mobility = np.sqrt(np.var(np.diff(channel_data)) / activity)\n",
    "            \n",
    "        # Append the features from this channel to the segment's feature vector\n",
    "        new_segment_features.extend([activity, mobility, *psd, *wavelet])\n",
    "        \n",
    "    return np.array(new_segment_features)\n",
    "\n",
    "def process_and_classify():\n",
    "    global new_data  # Declare new_data as a global variable\n",
    "    if new_data is not None:\n",
    "        try:\n",
    "            # Assuming the segment_data and extract_features functions are defined\n",
    "            new_data = new_data.iloc[625 : 1875]\n",
    "            new_data = new_data[channels]\n",
    "            new_features = extract_new_features(channels)\n",
    "            new_features = new_features.reshape(1, -1)\n",
    "            prediction = model.predict([new_features[0]])\n",
    "\n",
    "            # Update the label text and image based on the prediction\n",
    "            result_label.config(text=str(prediction[0]))\n",
    "            update_image(prediction[0])\n",
    "        except Exception as e:\n",
    "            status_label.config(text=f\"Error during processing: {e}\")\n",
    "    else:\n",
    "        status_label.config(text=\"No data loaded. Please load a CSV file first.\")\n",
    "\n",
    "def update_image(direction):\n",
    "    if direction.lower() == 'left':\n",
    "        image_path = \"F:/Graduation/picture1.png\"\n",
    "    else:\n",
    "        image_path = \"F:/Graduation/picture4.png\"\n",
    "    image = Image.open(image_path)\n",
    "    photo = ImageTk.PhotoImage(image)\n",
    "    direction_label.config(image=photo)\n",
    "    direction_label.image = photo  # Keep a reference!\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"EEG Direction Classifier\")\n",
    "\n",
    "# Load Button\n",
    "load_button = tk.Button(root, text=\"Load CSV\", command=load_data)\n",
    "load_button.pack()\n",
    "\n",
    "# Process and Classify Button\n",
    "process_button = tk.Button(root, text=\"Process and Classify\", command=process_and_classify)\n",
    "process_button.pack()\n",
    "\n",
    "# Label to display classification result\n",
    "result_label = Label(root, text=\"Result: None\", font=('Helvetica', 14))\n",
    "result_label.pack()\n",
    "\n",
    "# Label to display direction image\n",
    "direction_label = Label(root)\n",
    "direction_label.pack()\n",
    "\n",
    "# Status Label to display current status or errors\n",
    "status_label = Label(root, text=\"Awaiting action\", font=('Helvetica', 10))\n",
    "status_label.pack()\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
